# curtiz-japanese-nlp â€” WIP â˜£ï¸â˜¢ï¸ðŸ§ªðŸ§«ðŸ§¬âš—ï¸â˜¢ï¸â˜£ï¸

> N.B. All references to â€œCurtizâ€ are to version 2 of the Curtiz format (using `@` symbols), and not version 1 (using `â—Š` lozenges).

## Curtiz version 2 soft-specification
The Curtiz Markdown format for defining Japanese flashcards uses **Markdown headers**, e.g., the following header:

### @ ç§ @ ã‚ãŸã—
which is `### @ ç§ @ ã‚ãŸã—` in the original Markdown, as flashcards. That is, a flashcard-header has `#` symbols, whitespace, `@` symbol, whitespace, and then arbitrary text, separated by one or more ` @ ` separators. (`@` was chosen because it is easy to type on mobile and real keyboards, in Japanese and English.) The first text is treated as the prompt: thatâ€™s what the flashcard app will show. Text after the prompt are taken as acceptable answers.

So the following header accepts three answers for the same prompt:

### @ ç§ @ ã‚ãŸã— @ ã‚ãŸãã— @ ã‚ãŸã—

Next, any **Markdown bullets** immediately following the at-header starting with `@` are Curtiz-specific metadata.

Example:

### @ åƒ•ã®èŠ±ã®è‰² @ ã¼ãã®ã¯ãªã®ã„ã‚
- @fill åƒ•[ã®]èŠ±
- @fill èŠ±[ã®]è‰²
- @ åƒ• @ ã¼ã    @pos pronoun
- @ èŠ± @ ã¯ãª    @pos noun-common-general
- @ è‰² @ ã„ã‚    @pos noun-common-general

This example demonstrates both sub-quizzes that are currently supported:
- `@fill` allows for a fill-in-the-blank (perhaps where the prompt is shown, minus the text to be filled in), and
- `@` indicates a flashcard just like the `@`-headers: `prompt @ response`. These are amenable to plain flashcards on their own as well as fill-in-the-blank in the sentence. If the sub-prompt (in this bullet) cannot be found or uniquely determined in the header's prompt, then an `@omit` adverb can be optionally used to indicate the portion of the header prompt to be hidden. The optional `@pos` adverb contains the part-of-speech (as determined by MeCab), and facilitates disambiguiation of flashcards.

Both these optional adverbs are demonstrated below.

### @ ã“ã®ãŠã¯ãªã—ã‚’è©±ã™ @ ã“ã®ãŠã¯ãªã—ã‚’ã¯ãªã™
- @fill ã‚’
- @ è©± @ ã¯ãªã—    @pos noun-common-verbal_suru @omit ã¯ãªã—
- @ è©±ã™ @ ã¯ãªã™    @pos verb-general

**Furigana** can be automatically generated by this library: a `@furigana` line interleaves text and reading by enclosing both in braces and separating them by a caret, e.g., `{è©±}^{ã¯ãªã—}`. This is what it looks like:

## @ çŸ³ç‚­ã‚’é‹ã¶ @ ã›ããŸã‚“ã‚’ã¯ã“ã¶
- @furigana {çŸ³}^{ã›ã}{ç‚­}^{ãŸã‚“}ã‚’{é‹}^{ã¯ã“}ã¶
- @fill ã‚’    @pos particle-case
- @ çŸ³ç‚­ @ ã›ããŸã‚“    @pos noun-common-general
- @ é‹ã¶ @ ã¯ã“ã¶    @pos verb-general

**Translations** are also available, on a per-block or per-bullet level. For example:

### @ ç§ãŒæ¥ãŸ @ ã‚ãŸã—ãŒããŸ
- @translation @en I am here. @fr Je suis ici.
- @ ç§ @ ã‚ãŸã— @ ã‚ãŸãã— @ ã‚ãŸã— @t-en I @t-fr je @t-de Ich

When the `@translation` adverb is on its own bullet, it applies to the sentence. The language of the translation must be specified (in the above case, for the bullet-translation, English and French). Because of the format, the translation shouldnâ€™t use `@`-symbols.

The short-hand adverb for translation can also be placed on the header line, and it can be used for sub-quizzes. The short-hand combines the language into the adverb, i.e., `@t-en` for the English translation, `@t-de` for the German, etc. The language markers `en`, `fr`, etc., are currently informal and not enforced.

*N.B.* Translations arenâ€™t created by this library, but since this is serving as a soft-spec for the Curtiz format, I describe them here.

## This module's features

This module uses [MeCab](https://github.com/taku910/mecab/) with the [UniDic](https://osdn.net/projects/unidic/) dictionary, and [J.DepP](http://www.tkl.iis.u-tokyo.ac.jp/~ynaga/jdepp/) bunsetsu chunker to add readings, `@fill`-in-the-blank quizzes, and `@` flashcards into a Curtiz Markdown file.

> Make sure you have these three applications installed before attempting to use this!

It will add a reading to the header if none exists.

It will add sub-quizzes (`@fill` and `@`) and furigana if there is a special bullet under the header: `- @pleaseParse`. Furigana comes from analyzing the excellent [JmdictFurigana](https://github.com/Doublevil/JmdictFurigana) project (which itself builds on the Jmdict dictionary project).

***N.B.*** The first time this module is run, it will download and save the ~8 MB [JmdictFurigana](https://github.com/Doublevil/JmdictFurigana) database from GitHub and parse it into a ~25 MB JSON file, which might take several seconds. Subsequent runs of the module will read these files from the current directory and skip this step.

## Usage
This package provides:
1. a command-line utility that will consume an input file or standard input, and spit out the Markdown file annotated with readings and sub-quizzes; and
2. a JavaScript library to do this programmatically.

### Command-line utility
The command-line utility can be invoked on a file or can consume standard input. Make sure you have [Node.js](https://nodejs.org) installed, then in your terminal (Terminal.app in macOS, Command Prompt in Windows, xterm in Linux, etc.), run either of the following:

```
$ npx curtiz-japanese-nlp README.md
```
and replace `README.md` with the path to your Markdown file, or
```
$ cat README.md | npx curtiz-japanese-nlp
```

### Library API
Install this package into your JavaScript/TypeScript package via
```
$ npm install curtiz-japanese-nlp
```
Then in your JavaScript code, you may:
```js
const curtiz = require('curtiz-japanese-nlp'); 
```
In TypeScript or with ES2015 modules, you may:
```js
import * as curtiz from 'curtiz-japanese-nlp';
```

The following functions will then be available under the `curtiz` namespace.

#### `async function parseHeaderBlock(block: string[]): Promise<string[]>`
A `block` is an array of strings, one line per element, with the first line assumed to contain a Markdown header block (something starting with one or more `#` hash symbols).

`parseHeaderBlock` returns a [promise](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise) of an array of strings, which will contain annotated Markdown.

This is the core function provided by this library.

The remaining functions below are helper utility functions.

#### `function splitAtHeaders(text: string): string[][]`
This is intended to split the contents of a file (a single string `text`) into an array of blocks (each block being an array of strings itself, each string being a line of Markdown).

#### `async function parseAllHeaderBlocks(blocks: string[][], concurrentLimit: number = 8)`
This is intended to annotate an array of blocks (`blocks`), each block being an array of strings and each string being a line of Markdown.

The `concurrentLimit` argument allows you to limit the number of concurrent system calls to `mecab` and `jdepp` that are being made.

A promise for an array of blocks is returned.

You can use both these helper functions along with the primary function as follows, assuming you are inside an `async` function:
```js
let annotated = await curtiz.parseAllHeaderBlocks(curtiz.splitAtHeaders(fs.readFileSync('README.md', 'utf8')));
console.log(annotated.map(s => s.join('\n')).join('\n'));
```
The first line slurps the contents of `README.md` and splits it into blocks at Markdown header boundaries, then annotates them all.

The second line logs the entire annotated Markdown.

## Useful helpers

### MecabUnidic
Often it can be very helpful to inspect the output of MeCab-Unidic to understand what this module is doing. This library incldues a thin wrapper that translates Unidic parts-of-speech, conjugations, inflections, etc., into English (via tables [1](https://gist.github.com/masayu-a/e3eee0637c07d4019ec9), [2](https://gist.github.com/masayu-a/3e11168f9330e2d83a68), [3](https://gist.github.com/masayu-a/b3ce862336e47736e84f), published by GitHub user @masayu-a citing the work of Dr Irena Srdanovic), and exposes a command-line interface: simply pipe multi-line input into `mecabUnidic.js`, for example `cat text | ./mecabUnidic.js` or equivalently `cat text | node mecabUnidic.js`. A simple example on the command-line:
```shell
cat <<EOF | ./mecabUnidic.js
ã€Œã»ã‚‰ã€
ã‚ã‚ŒãŒå°å­¦æ ¡ã ã‚ˆã€‚ã€
EOF
```
This will print out the following Markdown table:

| Literal | Pronunciation | Lemma Reading | Lemma | Part of Speech                    | Inflection Type | Inflection         |
| ------- | ------------- | ------------- | ----- | --------------------------------- | --------------- | ------------------ |
| ã»ã‚‰    | ãƒ›ãƒ©          | ãƒ›ãƒ©          | ã»ã‚‰  | interjection-general              |                 |                    |
| ã€      |               |               | ã€    | supplementary_symbol-comma        |                 |                    |
|         |               |               |       |                                   |                 |                    |
| ã‚ã‚Œ    | ã‚¢ãƒ¬          | ã‚¢ãƒ¬          | å½¼ã‚Œ  | pronoun                           |                 |                    |
| ãŒ      | ã‚¬            | ã‚¬            | ãŒ    | particle-case                     |                 |                    |
| å°      | ã‚·ãƒ§ãƒ¼        | ã‚·ãƒ§ã‚¦        | å°    | prefix                            |                 |                    |
| å­¦æ ¡    | ã‚¬ãƒƒã‚³ãƒ¼      | ã‚¬ãƒƒã‚³ã‚¦      | å­¦æ ¡  | noun-common-general               |                 |                    |
| ã       | ãƒ€            | ãƒ€            | ã     | auxiliary_verb                    | auxiliary-da    | conclusive-general |
| ã‚ˆ      | ãƒ¨            | ãƒ¨            | ã‚ˆ    | particle-phrase_final             |                 |                    |
| ã€‚      |               |               | ã€‚    | supplementary_symbol-period       |                 |                    |
| ã€      |               |               | ã€    | supplementary_symbol-bracket_open |                 |                    |
|         |               |               |       |                                   |                 |                    |


### Awk
If you have a file containing just lines of text and you want to parse them all, this [Awk](https://developer.ibm.com/tutorials/l-awk1/) script can pre-process them to a format amenable for this tool:
```shell
cat text | awk '{if (NF>0) {print "## @ " $0 " @ \n- @pleaseParse"} else {print $0}}' | node index.js
```
